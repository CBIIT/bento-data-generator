{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field, fields, asdict\n",
    "import yaml\n",
    "from typing import List\n",
    "from collections import namedtuple, defaultdict, Counter\n",
    "import random\n",
    "import pandas as pd\n",
    "import sys\n",
    "from openpyxl import load_workbook, Workbook\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE CLASSES\n",
    "#dataclass for model properties\n",
    "@dataclass\n",
    "class ModelProperty:\n",
    "    name: str = field(default = \"\")\n",
    "    desc: str = field(default = \"\")\n",
    "    value_type: str = field(default = \"\")\n",
    "    value_list: List[str] = field(default_factory=list)\n",
    "    synthetic_value_list: List[str] = field(default_factory=list)\n",
    "    units: List[str] = field(default_factory=list)\n",
    "    pattern: str = field(default = \"\")\n",
    "    url: str = field(default = \"\")\n",
    "    req: bool = field(default = False)\n",
    "    private: bool = field(default = False)\n",
    "    minimum: str = field(default = \"\")\n",
    "    maximum: str = field(default = \"\")\n",
    "    exclusiveMinimum:  str = field(default = \"\")\n",
    "    exclusiveMaximum:  str = field(default = \"\")\n",
    "    \n",
    "    def emit_value(self):\n",
    "        property_data_value = \"\"\n",
    "        if self.synthetic_value_list:\n",
    "            property_data_value = random.choice(self.synthetic_value_list)\n",
    "            return property_data_value\n",
    "        if self.value_list:\n",
    "            property_data_value = random.choice(self.value_list)\n",
    "            return property_data_value\n",
    "        if self.value_type == 'string':\n",
    "            base_list = [\"a_bene_placito\",\n",
    "                         \"barba_crescit_caput_nescit\",\n",
    "                         \"cacatum_non_est_pictum\",\n",
    "                         \"damnant_quod_non_intellegunt\",\"e_causa_ignota\",\n",
    "                         \"faber_est_suae_quisque_fortunae\",\n",
    "                         \"Gallia_est_omnis_divisa_in_partes_tres\",\"haec_olim_meminisse_iuvabit\",\n",
    "                         \"id_quod_plerumque_accidit\",\"imperium_in_imperio\",\"labor_ipse_voluptas\",\n",
    "                         \"Macte_animo_Generose_puer_sic_itur_ad_astra\",\"nanos_gigantum_humeris_insidentes\",\n",
    "                         \"nascentes_morimur_finisque_ab_origine_pendet\",\"O_Tite_tute_Tati_tibi_tanta_tyranne_tulisti\",\n",
    "                         \"Obedientia_civium_urbis_felicitas\",\"pace_tua\",\"saltus_in_demonstrando\",\n",
    "                         \"salus_in_arduis\",\"sapiens_qui_prospicit\",\"scientia_et_labor\",\"scientia_et_sapientia\",\n",
    "                         \"scientia_imperii_decus_et_tutamen\",\"scientia,_aere_perennius\",\"scientiae_cedit_mare\",\n",
    "                         \"scientiae_et_patriae\"]\n",
    "            property_data_value = random.choice(base_list)\n",
    "            return property_data_value\n",
    "        if self.value_type == 'number':\n",
    "            if type(self.minimum) == float and type(self.maximum) == float:\n",
    "                property_data_value = random.uniform(self.minimum, self.maximum)\n",
    "            else:\n",
    "                property_data_value = random.uniform(10.0,1000.0)\n",
    "            property_data_value = round(property_data_value, 2)\n",
    "            return property_data_value\n",
    "        if self.value_type == 'boolean':\n",
    "            property_data_value = random.choice([True, False])\n",
    "            return property_data_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataclass for model nodes\n",
    "@dataclass\n",
    "class ModelNode:\n",
    "    name: str = field(default = \"\")\n",
    "    properties: List[ModelProperty] = field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataclass for the ends of a model relationship\n",
    "@dataclass\n",
    "class ModelEnds:\n",
    "    source_node: ModelNode\n",
    "    destination_node: ModelNode\n",
    "    multiplicity: str = field(default = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataclass for model relationships\n",
    "@dataclass\n",
    "class ModelEdge:\n",
    "    name: str\n",
    "    ends_list: List[ModelEnds] = field(default_factory=list)\n",
    "    properties_list: List[ModelProperty] = field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataclass for mock data nodes\n",
    "@dataclass\n",
    "class DataNode:\n",
    "    node_id: str\n",
    "    parent_node_id_list: list\n",
    "    child_node_id_list: list\n",
    "    node_type: str\n",
    "    node_attributes: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataclass for mock data relationships\n",
    "@dataclass\n",
    "class DataEdge:\n",
    "    edge_id: str\n",
    "    edge_type: str\n",
    "    edge_attributes: dict\n",
    "    source_node: DataNode\n",
    "    destination_node: DataNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Graph:\n",
    "    dict_of_data_nodes: defaultdict(list)\n",
    "    dict_of_data_edges: {}\n",
    "    \n",
    "    def print_data(self, node_type = 'all'):\n",
    "        if node_type == 'all':\n",
    "            for node_type_key in data_graph.dict_of_data_nodes:\n",
    "                node_values_dict = defaultdict(list)\n",
    "                df = pd.DataFrame()\n",
    "                for node in data_graph.dict_of_data_nodes[node_type_key]:\n",
    "                    node_values_dict['type'].append(node.node_type)\n",
    "                \n",
    "                if  node.parent_node_id_list:\n",
    "                    node_values_dict['parent_id'].append(node.parent_node_id_list[0])\n",
    "\n",
    "                node_values_dict['node_id'].append(node.node_id)\n",
    "                for node_prop in node.node_attributes:\n",
    "                    node_values_dict[node_prop].append(node.node_attributes[node_prop])\n",
    "                \n",
    "                for node_values_key in node_values_dict:\n",
    "                    df[node_values_key] = node_values_dict[node_values_key]\n",
    "                \n",
    "                file_name = node_type_key + \".csv\"\n",
    "                df.to_csv(file_name)\n",
    "            \n",
    "            return\n",
    "        else:\n",
    "            if node_type in data_graph.dict_of_data_nodes:\n",
    "                node_values_dict = defaultdict(list)\n",
    "                df = pd.DataFrame()\n",
    "                for node in data_graph.dict_of_data_nodes[node_type]:\n",
    "                    node_values_dict['type'].append(node.node_type)\n",
    "                \n",
    "                if  node.parent_node_id_list:\n",
    "                    node_values_dict['parent_id'].append(node.parent_node_id_list[0])\n",
    "                \n",
    "                node_values_dict['node_id'].append(node.node_id)\n",
    "                \n",
    "                for node_prop in node.node_attributes:\n",
    "                    node_values_dict[node_prop].append(node.node_attributes[node_prop])\n",
    "                \n",
    "                for node_values_key in node_values_dict:\n",
    "                    df[node_values_key] = node_values_dict[node_values_key]\n",
    "                \n",
    "                file_name = node_type_key + \".csv\"\n",
    "                df.to_csv(file_name)\n",
    "                return\n",
    "            else:\n",
    "                print(\"node type not found in graph.\")\n",
    "                return\n",
    "    \n",
    "    def fill_graph(self, listOfProps, model_nodes_dict, model_props_dict):\n",
    "        for node_type in self.dict_of_data_nodes:\n",
    "            listOfNodeProps = model_nodes_dict[node_type].properties\n",
    "            listOfDataNodes = self.dict_of_data_nodes[node_type]\n",
    "            for data_node in listOfDataNodes:\n",
    "                for prop in listOfNodeProps:\n",
    "                    if prop.name in listOfProps[data_node.node_type]:\n",
    "                        data_node.node_attributes[prop.name] = model_props_dict[prop.name].emit_value()\n",
    "        return\n",
    "    \n",
    "    def get_dict_of_data_nodes(self):\n",
    "        return self.dict_of_data_nodes\n",
    "    \n",
    "    def get_dict_of_data_edges(self):\n",
    "        return self.dict_of_data_edges\n",
    "    \n",
    "    def get_in_degree(self, input_node_id):\n",
    "        for key in self.dict_of_data_nodes:\n",
    "            for node in dict_of_data_nodes[key]:\n",
    "                if node.node_id == input_node_id:\n",
    "                    return len(node.parent_node_id_list)\n",
    "    \n",
    "    def get_out_degree(self, input_node_id):\n",
    "        for key in self.dict_of_data_nodes:\n",
    "            for node in dict_of_data_nodes[key]:\n",
    "                if node.node_id == input_node_id:\n",
    "                    return len(node.child_node_id_list)\n",
    "    \n",
    "    def summary(self):\n",
    "        summary = {}\n",
    "        summary['Nodes Summary'] = {}\n",
    "        summary['Edges Summary']  = {}\n",
    "        \n",
    "        for node_type in self.dict_of_data_nodes:\n",
    "            node_count = len(dict_of_data_nodes[node_type])\n",
    "            summary['Nodes Summary'].update({node_type: node_count})\n",
    "        \n",
    "        edge_type_list = []\n",
    "        for edge in dict_of_data_edges.values():\n",
    "            edge_type_list.append(edge.edge_type)\n",
    "        edge_type_counter = Counter(edge_type_list)\n",
    "        for edge_type, edge_type_count in edge_type_counter.items():\n",
    "            summary['Edges Summary'].update({edge_type: edge_type_count})\n",
    "        \n",
    "        return summary\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "######BEGIN READ SECTION######\n",
    "dict_of_model_properties = {}\n",
    "dict_of_model_nodes = {}\n",
    "model_graph = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration_files = 'configuration_files.yaml'\n",
    "with open(configuration_files) as f:\n",
    "    configuration_files = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ MODEL FILES AND FILE WITH SYNTHETIC VALUES\n",
    "#FOR BENTO\n",
    "NODE_FILE = configuration_files['NODE_FILE']\n",
    "PROP_FILE = configuration_files['PROP_FILE']\n",
    "SYNTHETIC_DATA_FILE = configuration_files['SYNTHETIC_DATA_FILE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_values_df = pd.read_excel(io = SYNTHETIC_DATA_FILE,\n",
    "                        sheet_name = \"Sheet1\",\n",
    "                        engine = \"openpyxl\",\n",
    "                        keep_default_na = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PROP_FILE) as f:\n",
    "    property_data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    for property_name in property_data['PropDefinitions'].keys():\n",
    "        property_value_type = property_data['PropDefinitions'][property_name]['Type']\n",
    "        name = property_name\n",
    "        desc = \"\"\n",
    "        req= \"\"\n",
    "        value_type = \"\"\n",
    "        value_list = []\n",
    "        synthetic_value_list = []\n",
    "        units = []\n",
    "        private = \"\"\n",
    "        pattern = \"\"\n",
    "        url = \"\"\n",
    "        minimum = \"\"\n",
    "        maximum = \"\"\n",
    "        exclusiveMinimum = \"\"\n",
    "        exclusiveMaximum = \"\"\n",
    "\n",
    "        if type(property_value_type) is str:\n",
    "            name = property_name\n",
    "            value_type = property_value_type\n",
    "            if 'Desc' in property_data['PropDefinitions'][property_name]:\n",
    "                desc = property_data['PropDefinitions'][property_name]['Desc']\n",
    "            if 'Req' in property_data['PropDefinitions'][property_name]:\n",
    "                req = property_data['PropDefinitions'][property_name]['Req']\n",
    "            if 'Private' in property_data['PropDefinitions'][property_name]:\n",
    "                private = property_data['PropDefinitions'][property_name]['Private']\n",
    "            if 'minimum' in property_data['PropDefinitions'][property_name]:\n",
    "                minimum = property_data['PropDefinitions'][property_name]['minimum']\n",
    "            if 'maximum' in property_data['PropDefinitions'][property_name]:\n",
    "                maximum = property_data['PropDefinitions'][property_name]['maximum']\n",
    "            if property_name in synthetic_values_df.columns:\n",
    "                synthetic_value_list = [x for x in synthetic_values_df[property_name].tolist() if x != '']\n",
    "                \n",
    "        if type(property_value_type) is list:\n",
    "            value_type = \"list\"\n",
    "            value_list = property_value_type\n",
    "            #add section on reading the url to create a value list if property_value_type contains a url.\n",
    "            if 'Desc' in property_data['PropDefinitions'][property_name]:\n",
    "                desc = property_data['PropDefinitions'][property_name]['Desc']\n",
    "            if 'Req' in property_data['PropDefinitions'][property_name]:\n",
    "                req = property_data['PropDefinitions'][property_name]['Req']\n",
    "            if 'Private' in property_data['PropDefinitions'][property_name]:\n",
    "                private = property_data['PropDefinitions'][property_name]['Private']\n",
    "            if property_name in synthetic_values_df.columns:\n",
    "                synthetic_value_list = [x for x in synthetic_values_df[property_name].tolist() if x != '']\n",
    "                \n",
    "        if type(property_value_type) is dict:\n",
    "            if 'Desc' in property_data['PropDefinitions'][property_name]:\n",
    "                desc = property_data['PropDefinitions'][property_name]['Desc']\n",
    "            if 'value_type' in property_value_type:\n",
    "                value_type = property_value_type['value_type']\n",
    "            if 'units' in property_value_type:\n",
    "                units = property_value_type['units']\n",
    "            if 'pattern' in property_value_type:\n",
    "                pattern = property_value_type['pattern']\n",
    "                value_type = \"regex\"\n",
    "            if 'Req' in property_data['PropDefinitions'][property_name]:\n",
    "                req = property_data['PropDefinitions'][property_name]['Req']\n",
    "            if 'Private' in property_data['PropDefinitions'][property_name]:\n",
    "                private = property_data['PropDefinitions'][property_name]['Private']\n",
    "            if 'minimum' in property_data['PropDefinitions'][property_name]:\n",
    "                minimum = property_data['PropDefinitions'][property_name]['minimum']\n",
    "            if 'maximum' in property_data['PropDefinitions'][property_name]:\n",
    "                maximum = property_data['PropDefinitions'][property_name]['maximum']\n",
    "            if property_name in synthetic_values_df.columns:\n",
    "                synthetic_value_list = [x for x in synthetic_values_df[property_name].tolist() if x != '']\n",
    "            \n",
    "        dict_of_model_properties[property_name] = ModelProperty(name = name, desc = desc, \n",
    "                                                                    value_type = value_type, value_list = value_list,\n",
    "                                                                    units = units, url = url, req = req, private = private, minimum = minimum, maximum = maximum,\n",
    "                                                                    exclusiveMinimum = exclusiveMinimum, exclusiveMaximum = exclusiveMaximum, synthetic_value_list = synthetic_value_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(NODE_FILE) as f:\n",
    "    node_data = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = node_data['Nodes']\n",
    "\n",
    "for node_name in nodes.keys():\n",
    "    #print(node_name, nodes[node_name]['Props'])\n",
    "    if nodes[node_name]['Props']:\n",
    "        property_list = [dict_of_model_properties[property_name] for property_name in nodes[node_name]['Props']]\n",
    "    else:\n",
    "        property_list = []\n",
    "    dict_of_model_nodes[node_name] = ModelNode(name = node_name, properties = property_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = node_data['Relationships']\n",
    "\n",
    "for edge_name in edges.keys():\n",
    "    Ends_list = []\n",
    "    Property_list = []\n",
    "    edge_multiplicity = edges[edge_name]['Mul']\n",
    "    \n",
    "    for edge_pair in edges[edge_name]['Ends']:\n",
    "        source_node = edge_pair['Src']\n",
    "        destination_node = edge_pair['Dst']\n",
    "        if 'Mul' in edge_pair:\n",
    "            edge_multiplicity = edge_pair['Mul']\n",
    "        Ends_list.append(ModelEnds(source_node = dict_of_model_nodes[source_node], destination_node = dict_of_model_nodes[destination_node], multiplicity = edge_multiplicity))\n",
    "        \n",
    "    \n",
    "    if edges[edge_name]['Props']:\n",
    "        property_list = [dict_of_model_properties[property_name] for property_name in edges[edge_name]['Props']]\n",
    "    else:\n",
    "        property_list = []\n",
    "    \n",
    "    model_graph[edge_name] = ModelEdge(name = edge_name, ends_list = Ends_list, properties_list = Property_list)\n",
    "#END READ MODEL FILES\n",
    "######END READ SECTION######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "######BEGIN SPAWN SECTION######\n",
    "dict_of_data_nodes = defaultdict(list)\n",
    "dict_of_data_edges = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ DATA SPECS FILE\n",
    "#FOR BENTO\n",
    "DATA_SPEC_FILE = configuration_files['DATA_SPEC_FILE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_SPEC_FILE) as f:\n",
    "    data_spec = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create head data node object\n",
    "head_node_type = data_spec['HeadNode']['name']\n",
    "head_node_count = data_spec['HeadNode']['count']\n",
    "id_prefix = data_spec['HeadNode']['Prefix']\n",
    "dst_node_type = head_node_type\n",
    "for count in range(head_node_count):\n",
    "    # node_id = id_prefix + \"_\" + str(random.randint(10**5, 10**6))\n",
    "    node_id = id_prefix + \"-\" + str(random.randint(10**5, 10**6))# for bento\n",
    "    parent_node_id_list = []\n",
    "    child_node_id_list = []\n",
    "    node_type = head_node_type\n",
    "    node_attributes = {}\n",
    "    data_node = DataNode(node_id = node_id, parent_node_id_list = parent_node_id_list, child_node_id_list = child_node_id_list,\n",
    "                         node_type = node_type, node_attributes = {})\n",
    "    dict_of_data_nodes[head_node_type].append(data_node)\n",
    "\n",
    "edge_specs = data_spec['RelationshipSpecs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create a skeleton data graph.\n",
    "#Create a skeleton data graph.\n",
    "def SpawnNodes():\n",
    "    created_children = []\n",
    "    for dst_node_type in edge_specs.keys():\n",
    "        if dst_node_type in dict_of_data_nodes and dst_node_type not in created_children:\n",
    "            dst_data_nodes_list = dict_of_data_nodes[dst_node_type]\n",
    "            for dst_data_node in dst_data_nodes_list:\n",
    "                for src_node_type in edge_specs[dst_node_type].keys():\n",
    "                    #print(dst_node_type, src_node_type)\n",
    "                    node_counter = 0\n",
    "                    if(edge_specs[dst_node_type][src_node_type]['SrcNodeCount'] == 'fixed'):\n",
    "                        node_counter = edge_specs[dst_node_type][src_node_type]['count']\n",
    "                \n",
    "                    if(edge_specs[dst_node_type][src_node_type]['SrcNodeCount'] == 'random'):\n",
    "                        minCount = edge_specs[dst_node_type][src_node_type]['minCount']\n",
    "                        maxCount = edge_specs[dst_node_type][src_node_type]['maxCount']\n",
    "                        node_counter = random.randint(minCount, maxCount)\n",
    "                        \n",
    "                    id_prefix = edge_specs[dst_node_type][src_node_type]['Prefix']\n",
    "                \n",
    "                    for count in range(node_counter):\n",
    "                        # node_id = id_prefix + \"_\" + str(random.randint(10**5, 10**6))\n",
    "                        node_id = id_prefix + \"-\" + str(random.randint(10**5, 10**6))\n",
    "                        parent_node_id_list = []\n",
    "                        parent_node_id_list.append(dst_data_node.node_id)\n",
    "                        child_node_id_list = []\n",
    "                        node_type = src_node_type\n",
    "                        node_attributes = {}\n",
    "                        src_data_node = DataNode(node_id = node_id, parent_node_id_list = parent_node_id_list, child_node_id_list = child_node_id_list,\n",
    "                                             node_type = node_type, node_attributes = {}) #source node created.\n",
    "                        dict_of_data_nodes[src_node_type].append(src_data_node) #source node added to the dict of nodes.\n",
    "                    \n",
    "                        dst_data_node.child_node_id_list.append(node_id) #add created source node to the child nodes list for dst node.\n",
    "                    \n",
    "                        edge_id = \"edge\" + \"_\" + str(random.randint(10**5, 10**6))\n",
    "                        edge_type = edge_specs[dst_node_type][src_node_type]['EdgeType']\n",
    "                        edge_attributes = {}\n",
    "                        data_edge = DataEdge(edge_id = edge_id, edge_type = edge_type, source_node = src_data_node, \n",
    "                                         destination_node = dst_data_node, edge_attributes = edge_attributes) #edge created.\n",
    "                        dict_of_data_edges[edge_id] = data_edge #edge added to the dict of edges.\n",
    "            created_children.append(dst_node_type)\n",
    "    data_graph = Graph(dict_of_data_nodes = dict_of_data_nodes, dict_of_data_edges = dict_of_data_edges)\n",
    "    return data_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create skeleton data graph\n",
    "data_graph = SpawnNodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nodes Summary': {'institution': 1,\n",
       "  'program': 1,\n",
       "  'study': 2,\n",
       "  'laboratory_procedure': 2,\n",
       "  'file': 32,\n",
       "  'sample': 12,\n",
       "  'study_subject': 4,\n",
       "  'follow_up': 8,\n",
       "  'diagnosis': 8,\n",
       "  'demographic_data': 8,\n",
       "  'stratification_factor': 8,\n",
       "  'therapeutic_procedure': 16},\n",
       " 'Edges Summary': {'program_of_institution': 1,\n",
       "  'study_of_program': 2,\n",
       "  'laboratory_procedure_of_program': 2,\n",
       "  'file_of_laboratory_procedure': 8,\n",
       "  'sample_processed_by': 4,\n",
       "  'study_subject_of_study': 4,\n",
       "  'fu_of_study_subject': 8,\n",
       "  'diagnosis_of_study_subject': 8,\n",
       "  'demographic_of_study_subject': 8,\n",
       "  'sample_of_study_subject': 8,\n",
       "  'sf_of_study_subject': 8,\n",
       "  'file_of_sample': 40}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine skeleton data graph\n",
    "data_graph.summary()\n",
    "######END SPAWN SECTION######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_FILE = configuration_files['ID_FILE']\n",
    "with open(ID_FILE) as f:\n",
    "    id_field_data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "relationship_node_dict = {}\n",
    "node_id_field_dict = {}\n",
    "\n",
    "for parent_id in data_spec['RelationshipSpecs']:\n",
    "    for node_id in data_spec['RelationshipSpecs'][parent_id]:\n",
    "        relationship_node = {}\n",
    "        relationship_node['node_id']=node_id\n",
    "        relationship_node['parent_id']=parent_id\n",
    "        if node_id in id_field_data['Properties']['id_fields']:\n",
    "            relationship_node['node_id_field']=id_field_data['Properties']['id_fields'][node_id]\n",
    "        else:\n",
    "            relationship_node['node_id_field']='node_id'\n",
    "        if parent_id in id_field_data['Properties']['id_fields']:\n",
    "            relationship_node['parent_id_field']=id_field_data['Properties']['id_fields'][parent_id]\n",
    "        else:\n",
    "            relationship_node['parent_id_field']='parent_id'\n",
    "        relationship_node_dict[node_id] = relationship_node\n",
    "\n",
    "for node_type in data_graph.dict_of_data_nodes:\n",
    "    if node_type in id_field_data['Properties']['id_fields']:\n",
    "        node_id_field_dict[node_type] = id_field_data['Properties']['id_fields'][node_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetParentIDField(node_type):\n",
    "    if node_type in relationship_node_dict:\n",
    "        # print(relationship_node_dict[node_type]['parent_id'])\n",
    "        return relationship_node_dict[node_type]['parent_id']+'.'+relationship_node_dict[node_type]['parent_id_field']\n",
    "    else:\n",
    "        return 'parent_id'\n",
    "def GetNodeIDField(node_type):\n",
    "    if node_type in node_id_field_dict:\n",
    "        return node_id_field_dict[node_type]\n",
    "    else:\n",
    "        return 'node_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "######BEGIN FILL SECTION######\n",
    "includePropsList = data_spec['IncludeProperties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_graph.fill_graph(listOfProps = includePropsList, \n",
    "                      model_nodes_dict = dict_of_model_nodes, \n",
    "                      model_props_dict = dict_of_model_properties)\n",
    "######END FILL SECTION######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all the records in each node with incorrect parent_id\n",
    "for x in range(0,2):\n",
    "    # run two times because in the first time running, the code might delete some parent node records after we delete some children node records\n",
    "    for node_type in data_graph.dict_of_data_nodes:\n",
    "        if data_graph.dict_of_data_nodes[node_type][0].parent_node_id_list:\n",
    "            remove_node_list = []\n",
    "            for node in data_graph.dict_of_data_nodes[node_type]:\n",
    "                p_id_list = []\n",
    "                for pn in data_graph.dict_of_data_nodes[relationship_node_dict[node_type]['parent_id']]:\n",
    "                    p_id_list.append(pn.node_id)\n",
    "                if node.parent_node_id_list[0] not in p_id_list:\n",
    "                    remove_node_list.append(node)\n",
    "            for remove_node in remove_node_list:\n",
    "                data_graph.dict_of_data_nodes[node_type].remove(remove_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "######PRINT DATA FILES######\n",
    "child_node_id_dict = {}\n",
    "child_node_id_list = []\n",
    "for node_type in data_graph.dict_of_data_nodes:\n",
    "    node_values_dict = defaultdict(list)\n",
    "    df = pd.DataFrame()\n",
    "    position = 0\n",
    "    for node in data_graph.dict_of_data_nodes[node_type]:\n",
    "        node_values_dict['type'].append(node.node_type)\n",
    "        if node.parent_node_id_list:\n",
    "            if node.node_id not in child_node_id_list:\n",
    "                node_values_dict[GetParentIDField(node_type)].append(node.parent_node_id_list[0]) #parent\n",
    "            else:\n",
    "                node_values_dict[GetParentIDField(node_type)].append(child_node_id_dict[node.node_id])\n",
    "                data_graph.dict_of_data_nodes[node_type][position].parent_node_id_list[0] = child_node_id_dict[node.node_id]\n",
    "            for parent_node in data_spec['RelationshipSpecs']:\n",
    "                for child_node in data_spec['RelationshipSpecs'][parent_node]:\n",
    "                    if child_node == node_type and parent_node != relationship_node_dict[node_type]['parent_id']:\n",
    "                        parent_node_id_list=[]\n",
    "                        for n in data_graph.dict_of_data_nodes[parent_node]:\n",
    "                            parent_node_id_list.append(n.node_id)\n",
    "                        if GetNodeIDField(parent_node) not in data_graph.dict_of_data_nodes[parent_node][0].node_attributes:\n",
    "                            node_values_dict[parent_node+'.'+GetNodeIDField(parent_node)].append(random.choice(parent_node_id_list))\n",
    "                        if GetNodeIDField(parent_node) in data_graph.dict_of_data_nodes[parent_node][0].node_attributes:\n",
    "                            new_parent_node_id_list = []\n",
    "                            for new_parent_node in data_graph.dict_of_data_nodes[parent_node]:\n",
    "                                new_parent_node_id_list.append(new_parent_node.node_attributes[GetNodeIDField(node_type)])\n",
    "                            node_values_dict[parent_node+'.'+GetNodeIDField(parent_node)].append(random.choice(new_parent_node_id_list))\n",
    "        if GetNodeIDField(node_type) not in node.node_attributes:\n",
    "            node_values_dict[GetNodeIDField(node_type)].append(node.node_id) #node\n",
    "        if GetNodeIDField(node_type) in node.node_attributes:\n",
    "            res = synthetic_values_df[GetNodeIDField(node_type)].tolist()\n",
    "            trim_res = [i for i in res if i]\n",
    "            # if the node_type has more nodes than the values of all usable node_id\n",
    "            if len(data_graph.dict_of_data_nodes[node_type]) > len(trim_res):\n",
    "                error_message = 'node ' + node_type + ' is running out of all usable node_ids from ' + GetNodeIDField(node_type) + '.'\n",
    "                # delete all previous generate tsv files\n",
    "                mydir = os.getcwd()\n",
    "                filelist = [ f for f in os.listdir(mydir) if f.endswith(\".tsv\") ]\n",
    "                for f in filelist:\n",
    "                    os.remove(os.path.join(mydir, f))\n",
    "                sys.exit(error_message)\n",
    "            new_node_id_list = []\n",
    "            for new_node in data_graph.dict_of_data_nodes[node_type]:\n",
    "                new_node_id_list.append(new_node.node_attributes[GetNodeIDField(node_type)])\n",
    "            new_node_id_list_counter = Counter(new_node_id_list)\n",
    "            reselect_value = False\n",
    "            #Check if the new node_id list has duplicate node_id\n",
    "            for value in new_node_id_list_counter.values():\n",
    "                if value > 1:\n",
    "                    reselect_value = True\n",
    "            if reselect_value == True:\n",
    "                new_value_list = random.sample(trim_res, len(new_node_id_list))\n",
    "                for i in range(len(data_graph.dict_of_data_nodes[node_type])):\n",
    "                    data_graph.dict_of_data_nodes[node_type][i].node_attributes[GetNodeIDField(node_type)] = new_value_list[i]\n",
    "            data_graph.dict_of_data_nodes[node_type][position].node_id = data_graph.dict_of_data_nodes[node_type][position].node_attributes[GetNodeIDField(node_type)]\n",
    "            for child_node_id in data_graph.dict_of_data_nodes[node_type][position].child_node_id_list:\n",
    "                child_node_id_list.append(child_node_id)\n",
    "                child_node_id_dict[child_node_id] = data_graph.dict_of_data_nodes[node_type][position].node_id\n",
    "        for node_prop in node.node_attributes:\n",
    "            # print(node_type)\n",
    "            # print(node.node_attributes)\n",
    "            node_values_dict[node_prop].append(node.node_attributes[node_prop])\n",
    "        position+=1\n",
    "    for node_values_key in node_values_dict:\n",
    "        df[node_values_key] = node_values_dict[node_values_key]\n",
    "    \n",
    "    file_name = configuration_files['OUTPUT_FOLDER'] + node_type + \".tsv\"\n",
    "    if not os.path.exists(configuration_files['OUTPUT_FOLDER']):\n",
    "        os.mkdir(configuration_files['OUTPUT_FOLDER'])\n",
    "    df.to_csv(file_name, sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
