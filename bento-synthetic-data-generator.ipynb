{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field, fields, asdict\n",
    "import yaml\n",
    "from typing import List\n",
    "from collections import namedtuple, defaultdict, Counter\n",
    "import random\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook, Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE CLASSES\n",
    "#dataclass for model properties\n",
    "@dataclass\n",
    "class ModelProperty:\n",
    "    name: str = field(default = \"\")\n",
    "    desc: str = field(default = \"\")\n",
    "    value_type: str = field(default = \"\")\n",
    "    value_list: List[str] = field(default_factory=list)\n",
    "    synthetic_value_list: List[str] = field(default_factory=list)\n",
    "    units: List[str] = field(default_factory=list)\n",
    "    pattern: str = field(default = \"\")\n",
    "    url: str = field(default = \"\")\n",
    "    req: bool = field(default = False)\n",
    "    private: bool = field(default = False)\n",
    "    minimum: str = field(default = \"\")\n",
    "    maximum: str = field(default = \"\")\n",
    "    exclusiveMinimum:  str = field(default = \"\")\n",
    "    exclusiveMaximum:  str = field(default = \"\")\n",
    "    \n",
    "    def emit_value(self):\n",
    "        property_data_value = \"\"\n",
    "        if self.synthetic_value_list:\n",
    "            property_data_value = random.choice(self.synthetic_value_list)\n",
    "            return property_data_value\n",
    "        if self.value_list:\n",
    "            property_data_value = random.choice(self.value_list)\n",
    "            return property_data_value\n",
    "        if self.value_type == 'string':\n",
    "            base_list = [\"a_bene_placito\",\n",
    "                         \"barba_crescit_caput_nescit\",\n",
    "                         \"cacatum_non_est_pictum\",\n",
    "                         \"damnant_quod_non_intellegunt\",\"e_causa_ignota\",\n",
    "                         \"faber_est_suae_quisque_fortunae\",\n",
    "                         \"Gallia_est_omnis_divisa_in_partes_tres\",\"haec_olim_meminisse_iuvabit\",\n",
    "                         \"id_quod_plerumque_accidit\",\"imperium_in_imperio\",\"labor_ipse_voluptas\",\n",
    "                         \"Macte_animo_Generose_puer_sic_itur_ad_astra\",\"nanos_gigantum_humeris_insidentes\",\n",
    "                         \"nascentes_morimur_finisque_ab_origine_pendet\",\"O_Tite_tute_Tati_tibi_tanta_tyranne_tulisti\",\n",
    "                         \"Obedientia_civium_urbis_felicitas\",\"pace_tua\",\"saltus_in_demonstrando\",\n",
    "                         \"salus_in_arduis\",\"sapiens_qui_prospicit\",\"scientia_et_labor\",\"scientia_et_sapientia\",\n",
    "                         \"scientia_imperii_decus_et_tutamen\",\"scientia,_aere_perennius\",\"scientiae_cedit_mare\",\n",
    "                         \"scientiae_et_patriae\"]\n",
    "            property_data_value = random.choice(base_list)\n",
    "            return property_data_value\n",
    "        if self.value_type == 'number':\n",
    "            if type(self.minimum) == float and type(self.maximum) == float:\n",
    "                property_data_value = random.uniform(self.minimum, self.maximum)\n",
    "            else:\n",
    "                property_data_value = random.uniform(10.0,1000.0)\n",
    "            property_data_value = round(property_data_value, 2)\n",
    "            return property_data_value\n",
    "        if self.value_type == 'boolean':\n",
    "            property_data_value = random.choice([True, False])\n",
    "            return property_data_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataclass for model nodes\n",
    "@dataclass\n",
    "class ModelNode:\n",
    "    name: str = field(default = \"\")\n",
    "    properties: List[ModelProperty] = field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataclass for the ends of a model relationship\n",
    "@dataclass\n",
    "class ModelEnds:\n",
    "    source_node: ModelNode\n",
    "    destination_node: ModelNode\n",
    "    multiplicity: str = field(default = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataclass for model relationships\n",
    "@dataclass\n",
    "class ModelEdge:\n",
    "    name: str\n",
    "    ends_list: List[ModelEnds] = field(default_factory=list)\n",
    "    properties_list: List[ModelProperty] = field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataclass for mock data nodes\n",
    "@dataclass\n",
    "class DataNode:\n",
    "    node_id: str\n",
    "    parent_node_id_list: list\n",
    "    child_node_id_list: list\n",
    "    node_type: str\n",
    "    node_attributes: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataclass for mock data relationships\n",
    "@dataclass\n",
    "class DataEdge:\n",
    "    edge_id: str\n",
    "    edge_type: str\n",
    "    edge_attributes: dict\n",
    "    source_node: DataNode\n",
    "    destination_node: DataNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Graph:\n",
    "    dict_of_data_nodes: defaultdict(list)\n",
    "    dict_of_data_edges: {}\n",
    "    \n",
    "    def print_data(self, node_type = 'all'):\n",
    "        if node_type == 'all':\n",
    "            for node_type_key in data_graph.dict_of_data_nodes:\n",
    "                node_values_dict = defaultdict(list)\n",
    "                df = pd.DataFrame()\n",
    "                for node in data_graph.dict_of_data_nodes[node_type_key]:\n",
    "                    node_values_dict['type'].append(node.node_type)\n",
    "                \n",
    "                if  node.parent_node_id_list:\n",
    "                    node_values_dict['parent_id'].append(node.parent_node_id_list[0])\n",
    "\n",
    "                node_values_dict['node_id'].append(node.node_id)\n",
    "                for node_prop in node.node_attributes:\n",
    "                    node_values_dict[node_prop].append(node.node_attributes[node_prop])\n",
    "                \n",
    "                for node_values_key in node_values_dict:\n",
    "                    df[node_values_key] = node_values_dict[node_values_key]\n",
    "                \n",
    "                file_name = node_type_key + \".csv\"\n",
    "                df.to_csv(file_name)\n",
    "            \n",
    "            return\n",
    "        else:\n",
    "            if node_type in data_graph.dict_of_data_nodes:\n",
    "                node_values_dict = defaultdict(list)\n",
    "                df = pd.DataFrame()\n",
    "                for node in data_graph.dict_of_data_nodes[node_type]:\n",
    "                    node_values_dict['type'].append(node.node_type)\n",
    "                \n",
    "                if  node.parent_node_id_list:\n",
    "                    node_values_dict['parent_id'].append(node.parent_node_id_list[0])\n",
    "                \n",
    "                node_values_dict['node_id'].append(node.node_id)\n",
    "                \n",
    "                for node_prop in node.node_attributes:\n",
    "                    node_values_dict[node_prop].append(node.node_attributes[node_prop])\n",
    "                \n",
    "                for node_values_key in node_values_dict:\n",
    "                    df[node_values_key] = node_values_dict[node_values_key]\n",
    "                \n",
    "                file_name = node_type_key + \".csv\"\n",
    "                df.to_csv(file_name)\n",
    "                return\n",
    "            else:\n",
    "                print(\"node type not found in graph.\")\n",
    "                return\n",
    "    \n",
    "    def fill_graph(self, listOfProps, model_nodes_dict, model_props_dict):\n",
    "        for node_type in self.dict_of_data_nodes:\n",
    "            listOfNodeProps = model_nodes_dict[node_type].properties\n",
    "            listOfDataNodes = self.dict_of_data_nodes[node_type]\n",
    "            for data_node in listOfDataNodes:\n",
    "                for prop in listOfNodeProps:\n",
    "                    if prop.name in listOfProps:\n",
    "                        data_node.node_attributes[prop.name] = model_props_dict[prop.name].emit_value()\n",
    "        return\n",
    "    \n",
    "    def get_dict_of_data_nodes(self):\n",
    "        return self.dict_of_data_nodes\n",
    "    \n",
    "    def get_dict_of_data_edges(self):\n",
    "        return self.dict_of_data_edges\n",
    "    \n",
    "    def get_in_degree(self, input_node_id):\n",
    "        for key in self.dict_of_data_nodes:\n",
    "            for node in dict_of_data_nodes[key]:\n",
    "                if node.node_id == input_node_id:\n",
    "                    return len(node.parent_node_id_list)\n",
    "    \n",
    "    def get_out_degree(self, input_node_id):\n",
    "        for key in self.dict_of_data_nodes:\n",
    "            for node in dict_of_data_nodes[key]:\n",
    "                if node.node_id == input_node_id:\n",
    "                    return len(node.child_node_id_list)\n",
    "    \n",
    "    def summary(self):\n",
    "        summary = {}\n",
    "        summary['Nodes Summary'] = {}\n",
    "        summary['Edges Summary']  = {}\n",
    "        \n",
    "        for node_type in self.dict_of_data_nodes:\n",
    "            node_count = len(dict_of_data_nodes[node_type])\n",
    "            summary['Nodes Summary'].update({node_type: node_count})\n",
    "        \n",
    "        edge_type_list = []\n",
    "        for edge in dict_of_data_edges.values():\n",
    "            edge_type_list.append(edge.edge_type)\n",
    "        edge_type_counter = Counter(edge_type_list)\n",
    "        for edge_type, edge_type_count in edge_type_counter.items():\n",
    "            summary['Edges Summary'].update({edge_type: edge_type_count})\n",
    "        \n",
    "        return summary\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "######BEGIN READ SECTION######\n",
    "dict_of_model_properties = {}\n",
    "dict_of_model_nodes = {}\n",
    "model_graph = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ MODEL FILES AND FILE WITH SYNTHETIC VALUES\n",
    "NODE_FILE = \"icdc-model.yaml\"\n",
    "PROP_FILE = \"icdc-model-props.yaml\"\n",
    "SYNTHETIC_DATA_FILE = \"synthetic_data_values.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_values_df = pd.read_excel(io = SYNTHETIC_DATA_FILE,\n",
    "                        sheet_name = \"Sheet1\",\n",
    "                        engine = \"openpyxl\",\n",
    "                        keep_default_na = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PROP_FILE) as f:\n",
    "    property_data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    for property_name in property_data['PropDefinitions'].keys():\n",
    "        property_value_type = property_data['PropDefinitions'][property_name]['Type']\n",
    "        name = property_name\n",
    "        desc = \"\"\n",
    "        req= \"\"\n",
    "        value_type = \"\"\n",
    "        value_list = []\n",
    "        synthetic_value_list = []\n",
    "        units = []\n",
    "        private = \"\"\n",
    "        pattern = \"\"\n",
    "        url = \"\"\n",
    "        minimum = \"\"\n",
    "        maximum = \"\"\n",
    "        exclusiveMinimum = \"\"\n",
    "        exclusiveMaximum = \"\"\n",
    "\n",
    "        if type(property_value_type) is str:\n",
    "            name = property_name\n",
    "            value_type = property_value_type\n",
    "            if 'Desc' in property_data['PropDefinitions'][property_name]:\n",
    "                desc = property_data['PropDefinitions'][property_name]['Desc']\n",
    "            if 'Req' in property_data['PropDefinitions'][property_name]:\n",
    "                req = property_data['PropDefinitions'][property_name]['Req']\n",
    "            if 'Private' in property_data['PropDefinitions'][property_name]:\n",
    "                private = property_data['PropDefinitions'][property_name]['Private']\n",
    "            if 'minimum' in property_data['PropDefinitions'][property_name]:\n",
    "                minimum = property_data['PropDefinitions'][property_name]['minimum']\n",
    "            if 'maximum' in property_data['PropDefinitions'][property_name]:\n",
    "                maximum = property_data['PropDefinitions'][property_name]['maximum']\n",
    "            if property_name in synthetic_values_df.columns:\n",
    "                synthetic_value_list = [x for x in synthetic_values_df[property_name].tolist() if x != '']\n",
    "                \n",
    "        if type(property_value_type) is list:\n",
    "            value_type = \"list\"\n",
    "            value_list = property_value_type\n",
    "            #add section on reading the url to create a value list if property_value_type contains a url.\n",
    "            if 'Desc' in property_data['PropDefinitions'][property_name]:\n",
    "                desc = property_data['PropDefinitions'][property_name]['Desc']\n",
    "            if 'Req' in property_data['PropDefinitions'][property_name]:\n",
    "                req = property_data['PropDefinitions'][property_name]['Req']\n",
    "            if 'Private' in property_data['PropDefinitions'][property_name]:\n",
    "                private = property_data['PropDefinitions'][property_name]['Private']\n",
    "            if property_name in synthetic_values_df.columns:\n",
    "                synthetic_value_list = [x for x in synthetic_values_df[property_name].tolist() if x != '']\n",
    "                \n",
    "        if type(property_value_type) is dict:\n",
    "            if 'Desc' in property_data['PropDefinitions'][property_name]:\n",
    "                desc = property_data['PropDefinitions'][property_name]['Desc']\n",
    "            if 'value_type' in property_value_type:\n",
    "                value_type = property_value_type['value_type']\n",
    "            if 'units' in property_value_type:\n",
    "                units = property_value_type['units']\n",
    "            if 'pattern' in property_value_type:\n",
    "                pattern = property_value_type['pattern']\n",
    "                value_type = \"regex\"\n",
    "            if 'Req' in property_data['PropDefinitions'][property_name]:\n",
    "                req = property_data['PropDefinitions'][property_name]['Req']\n",
    "            if 'Private' in property_data['PropDefinitions'][property_name]:\n",
    "                private = property_data['PropDefinitions'][property_name]['Private']\n",
    "            if 'minimum' in property_data['PropDefinitions'][property_name]:\n",
    "                minimum = property_data['PropDefinitions'][property_name]['minimum']\n",
    "            if 'maximum' in property_data['PropDefinitions'][property_name]:\n",
    "                maximum = property_data['PropDefinitions'][property_name]['maximum']\n",
    "            if property_name in synthetic_values_df.columns:\n",
    "                synthetic_value_list = [x for x in synthetic_values_df[property_name].tolist() if x != '']\n",
    "            \n",
    "        dict_of_model_properties[property_name] = ModelProperty(name = name, desc = desc, \n",
    "                                                                    value_type = value_type, value_list = value_list,\n",
    "                                                                    units = units, url = url, req = req, private = private, minimum = minimum, maximum = maximum,\n",
    "                                                                    exclusiveMinimum = exclusiveMinimum, exclusiveMaximum = exclusiveMaximum, synthetic_value_list = synthetic_value_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(NODE_FILE) as f:\n",
    "    node_data = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = node_data['Nodes']\n",
    "\n",
    "for node_name in nodes.keys():\n",
    "    #print(node_name, nodes[node_name]['Props'])\n",
    "    if nodes[node_name]['Props']:\n",
    "        property_list = [dict_of_model_properties[property_name] for property_name in nodes[node_name]['Props']]\n",
    "    else:\n",
    "        property_list = []\n",
    "    dict_of_model_nodes[node_name] = ModelNode(name = node_name, properties = property_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = node_data['Relationships']\n",
    "\n",
    "for edge_name in edges.keys():\n",
    "    Ends_list = []\n",
    "    Property_list = []\n",
    "    edge_multiplicity = edges[edge_name]['Mul']\n",
    "    \n",
    "    for edge_pair in edges[edge_name]['Ends']:\n",
    "        source_node = edge_pair['Src']\n",
    "        destination_node = edge_pair['Dst']\n",
    "        if 'Mul' in edge_pair:\n",
    "            edge_multiplicity = edge_pair['Mul']\n",
    "        Ends_list.append(ModelEnds(source_node = dict_of_model_nodes[source_node], destination_node = dict_of_model_nodes[destination_node], multiplicity = edge_multiplicity))\n",
    "        \n",
    "    \n",
    "    if edges[edge_name]['Props']:\n",
    "        property_list = [dict_of_model_properties[property_name] for property_name in edges[edge_name]['Props']]\n",
    "    else:\n",
    "        property_list = []\n",
    "    \n",
    "    model_graph[edge_name] = ModelEdge(name = edge_name, ends_list = Ends_list, properties_list = Property_list)\n",
    "#END READ MODEL FILES\n",
    "######END READ SECTION######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "######BEGIN SPAWN SECTION######\n",
    "dict_of_data_nodes = defaultdict(list)\n",
    "dict_of_data_edges = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ DATA SPECS FILE\n",
    "DATA_SPEC_FILE = \"./icdc-mock-data-specs_2.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_SPEC_FILE) as f:\n",
    "    data_spec = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create head data node object\n",
    "head_node_type = data_spec['HeadNode']['name']\n",
    "head_node_count = data_spec['HeadNode']['count']\n",
    "id_prefix = data_spec['HeadNode']['Prefix']\n",
    "dst_node_type = head_node_type\n",
    "for count in range(head_node_count):\n",
    "    node_id = id_prefix + \"_\" + str(random.randint(10**5, 10**6))\n",
    "    parent_node_id_list = []\n",
    "    child_node_id_list = []\n",
    "    node_type = head_node_type\n",
    "    node_attributes = {}\n",
    "    data_node = DataNode(node_id = node_id, parent_node_id_list = parent_node_id_list, child_node_id_list = child_node_id_list,\n",
    "                         node_type = node_type, node_attributes = {})\n",
    "    dict_of_data_nodes[head_node_type].append(data_node)\n",
    "\n",
    "edge_specs = data_spec['RelationshipSpecs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create a skeleton data graph.\n",
    "#Create a skeleton data graph.\n",
    "def SpawnNodes():\n",
    "    created_children = []\n",
    "    for dst_node_type in edge_specs.keys():\n",
    "        if dst_node_type in dict_of_data_nodes and dst_node_type not in created_children:\n",
    "            dst_data_nodes_list = dict_of_data_nodes[dst_node_type]\n",
    "            for dst_data_node in dst_data_nodes_list:\n",
    "                for src_node_type in edge_specs[dst_node_type].keys():\n",
    "                    #print(dst_node_type, src_node_type)\n",
    "                    node_counter = 0\n",
    "                    if(edge_specs[dst_node_type][src_node_type]['SrcNodeCount'] == 'fixed'):\n",
    "                        node_counter = edge_specs[dst_node_type][src_node_type]['count']\n",
    "                \n",
    "                    if(edge_specs[dst_node_type][src_node_type]['SrcNodeCount'] == 'random'):\n",
    "                        minCount = edge_specs[dst_node_type][src_node_type]['minCount']\n",
    "                        maxCount = edge_specs[dst_node_type][src_node_type]['maxCount']\n",
    "                        node_counter = random.randint(minCount, maxCount)\n",
    "                        \n",
    "                    id_prefix = edge_specs[dst_node_type][src_node_type]['Prefix']\n",
    "                \n",
    "                    for count in range(node_counter):\n",
    "                        node_id = id_prefix + \"_\" + str(random.randint(10**5, 10**6))\n",
    "                        parent_node_id_list = []\n",
    "                        parent_node_id_list.append(dst_data_node.node_id)\n",
    "                        child_node_id_list = []\n",
    "                        node_type = src_node_type\n",
    "                        node_attributes = {}\n",
    "                        src_data_node = DataNode(node_id = node_id, parent_node_id_list = parent_node_id_list, child_node_id_list = child_node_id_list,\n",
    "                                             node_type = node_type, node_attributes = {}) #source node created.\n",
    "                        dict_of_data_nodes[src_node_type].append(src_data_node) #source node added to the dict of nodes.\n",
    "                    \n",
    "                        dst_data_node.child_node_id_list.append(node_id) #add created source node to the child nodes list for dst node.\n",
    "                    \n",
    "                        edge_id = \"edge\" + \"_\" + str(random.randint(10**5, 10**6))\n",
    "                        edge_type = edge_specs[dst_node_type][src_node_type]['EdgeType']\n",
    "                        edge_attributes = {}\n",
    "                        data_edge = DataEdge(edge_id = edge_id, edge_type = edge_type, source_node = src_data_node, \n",
    "                                         destination_node = dst_data_node, edge_attributes = edge_attributes) #edge created.\n",
    "                        dict_of_data_edges[edge_id] = data_edge #edge added to the dict of edges.\n",
    "            created_children.append(dst_node_type)\n",
    "    data_graph = Graph(dict_of_data_nodes = dict_of_data_nodes, dict_of_data_edges = dict_of_data_edges)\n",
    "    return data_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create skeleton data graph\n",
    "data_graph = SpawnNodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nodes Summary': {'program': 1,\n",
       "  'study': 2,\n",
       "  'case': 4,\n",
       "  'sample': 22,\n",
       "  'diagnosis': 4,\n",
       "  'demographic': 4,\n",
       "  'file': 22},\n",
       " 'Edges Summary': {'member_of': 6, 'of_case': 30, 'of_sample': 22}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine skeleton data graph\n",
    "data_graph.summary()\n",
    "######END SPAWN SECTION######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "######BEGIN FILL SECTION######\n",
    "includePropsList = data_spec['IncludeProperties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_graph.fill_graph(listOfProps = includePropsList, \n",
    "                      model_nodes_dict = dict_of_model_nodes, \n",
    "                      model_props_dict = dict_of_model_properties)\n",
    "######END FILL SECTION######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "######PRINT DATA FILES######\n",
    "for node_type in data_graph.dict_of_data_nodes:\n",
    "    node_values_dict = defaultdict(list)\n",
    "    df = pd.DataFrame()\n",
    "    for node in data_graph.dict_of_data_nodes[node_type]:\n",
    "        node_values_dict['type'].append(node.node_type)\n",
    "        if  node.parent_node_id_list:\n",
    "            node_values_dict['parent_id'].append(node.parent_node_id_list[0])\n",
    "        node_values_dict['node_id'].append(node.node_id)\n",
    "        for node_prop in node.node_attributes:\n",
    "            node_values_dict[node_prop].append(node.node_attributes[node_prop])\n",
    "    \n",
    "    for node_values_key in node_values_dict:\n",
    "        df[node_values_key] = node_values_dict[node_values_key]\n",
    "    \n",
    "    file_name = node_type + \".tsv\"\n",
    "    df.to_csv(file_name, sep = \"\\t\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
